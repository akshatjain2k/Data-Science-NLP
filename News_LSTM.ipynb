{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhOVztKP7iCK0a/mi03Ube",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatjain2k/Data-Science-NLP/blob/Amey/News_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "X5teMmGtTARM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from collections import Counter\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r\"/content/not_preprocessed_data.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0ctyOsADTVcI",
        "outputId": "3a32b490-a370-4802-993a-17264c195f5f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        article_body            category\n",
              "0  Long COVID community, which is an open and gro...         Partnership\n",
              "1  Government test prep platform Adda247 on Octob...             Funding\n",
              "2  Private equity and venture capital investments...  Merger/Acquisition\n",
              "3  Digital book-keeping startup Khatabook said on...             Funding\n",
              "4  Events are always important and exciting to or...            Research"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfdfbad1-2785-4a08-b237-7a59c2c1dd26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_body</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Long COVID community, which is an open and gro...</td>\n",
              "      <td>Partnership</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Government test prep platform Adda247 on Octob...</td>\n",
              "      <td>Funding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Private equity and venture capital investments...</td>\n",
              "      <td>Merger/Acquisition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Digital book-keeping startup Khatabook said on...</td>\n",
              "      <td>Funding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Events are always important and exciting to or...</td>\n",
              "      <td>Research</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfdfbad1-2785-4a08-b237-7a59c2c1dd26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfdfbad1-2785-4a08-b237-7a59c2c1dd26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfdfbad1-2785-4a08-b237-7a59c2c1dd26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.category.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxIfxWJETWw-",
        "outputId": "5c712f36-0fbb-41d8-a3b0-0eb63edba3ea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Partnership           1587\n",
              "IPO                   1413\n",
              "Merger/Acquisition     990\n",
              "Finance                989\n",
              "Conference News        892\n",
              "Funding                728\n",
              "Research               469\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropiing research category because of less data points\n",
        "df = df.drop(df[df['category'] == 'Research'].index)"
      ],
      "metadata": {
        "id": "RCV11gYLToju"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Label Encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['category'] = le.fit_transform(df['category'])\n",
        "print(df['category'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDbQ5Iq3TsEM",
        "outputId": "1311de1d-7329-4c8d-8f8f-030f07c82bc6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5    1587\n",
            "3    1413\n",
            "4     990\n",
            "1     989\n",
            "0     892\n",
            "2     728\n",
            "Name: category, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.article_body, df.category, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHnCj9PNU8EV",
        "outputId": "26d7864a-026a-4eec-97a3-e21df92a9f64"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5279,)\n",
            "(1320,)\n",
            "(5279,)\n",
            "(1320,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def preprocess_string(word):\n",
        "  \n",
        "  # Remove punctuation\n",
        "  s = re.sub(r'[^\\w\\s]', '', word)\n",
        "  \n",
        "  # Convert to lowercase\n",
        "  s = s.lower()\n",
        "\n",
        "  # Remove extra whitespaces\n",
        "  text = re.sub(r'\\s+', ' ', s)\n",
        "\n",
        "  # Remove numbers\n",
        "  text = re.sub(r\"\\d\", '', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "Pq2iRk1JUNFB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "#loading the english language small model of spacy\n",
        "en = spacy.load('en_core_web_sm')\n",
        "stopwords = en.Defaults.stop_words\n",
        "def create_word_list(x_train):\n",
        "    word_list = []\n",
        "    stop_words = set(en.Defaults.stop_words)\n",
        "    for sent in x_train:\n",
        "        for word in sent.lower().split(' '):\n",
        "            word = preprocess_string(word)\n",
        "            if word not in stop_words and word != '':\n",
        "                word_list.append(word)\n",
        "    return word_list\n",
        "word_list = create_word_list(X_train)"
      ],
      "metadata": {
        "id": "dNUgBuVlWBoW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(x_train, x_test):\n",
        "    corpus = Counter(word_list)\n",
        "    corpus_ = sorted(corpus.items(), key = lambda x: x[1], reverse=True)[:10000]\n",
        "    onehot_dict = {w[0]:i+1 for i, w in enumerate(corpus_)}\n",
        "\n",
        "    final_list_train,final_list_test = [],[]\n",
        "    for sent in x_train:\n",
        "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
        "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
        "    for sent in x_test:\n",
        "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
        "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
        "            \n",
        "    return np.array(final_list_train),np.array(final_list_test),onehot_dict"
      ],
      "metadata": {
        "id": "ABAfC1VbXRHi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, vocab = tokenize(X_train, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGOxcALRYu8d",
        "outputId": "d2b7cc94-ae45-4b27-efda-c72c265968b5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-2a1b652f63bd>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(final_list_train),np.array(final_list_test),onehot_dict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1NRSDojZBt_",
        "outputId": "41a0fdfc-2130-4f1a-9743-2955b914c11b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([48, 101, 21, 1876, 7, 200, 3, 4, 940, 2278, 18, 3953, 1, 258, 254, 539, 1541, 4259, 8754, 2107, 3449, 557, 3953, 86, 7932, 2494, 1725, 3175, 29, 2238, 41, 4100, 9753, 5566, 6741, 7263, 1542, 7933, 5915, 160, 5026, 2441, 5, 3175, 29, 2238, 5, 823, 605, 5916, 18, 31, 263, 52, 95, 41, 3953, 3953, 6742, 3953, 2239, 6742, 2239, 905, 160, 160, 605, 170, 5027, 101, 293, 615, 724, 6743, 3953, 24, 67, 1877, 4613, 5296, 103, 1876, 43, 366, 615, 2279, 52, 9754, 3816, 951, 2442, 346, 65, 1293, 977, 3084, 1, 539, 103, 74, 3176, 29, 2278, 9755, 4260, 2495, 652, 370, 3953, 3274, 4614, 790, 989, 940, 2278, 165, 1082, 484, 318, 894, 5916, 1, 1877, 760, 113, 1876, 7, 17, 3, 4, 146, 16, 165, 246, 47, 231, 48, 101, 1168, 143, 1207, 8, 47, 5297, 48, 101, 106, 2550, 235, 1571, 15, 145, 28, 22, 101, 952, 63, 197, 355, 2280, 21, 3450, 910, 211, 18, 3954, 320, 31, 1457, 238, 21, 4419]),\n",
              "       list([1876, 7, 5567, 47, 1, 204, 367, 146, 48, 101, 16, 3, 4, 88, 232, 1317, 14, 1383, 16, 569, 507, 31, 22, 117, 1876, 2281, 183, 895, 30, 15, 5567, 197, 503, 547, 21, 4419, 355, 2280, 3450, 910, 86, 1361, 1001, 5028, 17, 598, 16, 232, 8, 653, 1758, 6744, 164, 16, 327, 28, 22, 1417, 1122, 647, 17, 48, 101, 749, 1417, 2380, 236, 87, 28, 3275, 1106, 4261, 2282, 9756, 236, 7264, 562, 65, 87, 7, 7265, 4613, 5296, 103, 175, 113, 1876, 152, 1122, 695, 265, 1834, 3569, 5568, 3276, 236, 265, 1149, 6295, 9, 1138, 6745, 5917, 5296, 2240, 1876, 17, 1043, 3, 4, 16, 231, 9, 1835, 3, 4, 131, 146, 16, 146, 16, 5029, 48, 2939, 123, 680, 23, 707, 157, 5, 806, 63, 119, 5, 749, 118, 15, 5567, 1189, 2496, 8, 16, 210, 66, 1959, 171, 1800, 197, 3570, 23, 183, 259, 72, 23, 6, 3817, 5298, 2810, 1057, 460, 103, 3005, 109, 1959, 605, 417, 65, 8, 200, 31, 288, 1094, 236, 1801, 1169, 2731, 101, 7, 119, 24, 47, 1, 1877, 760, 113, 1876, 48, 101, 21, 2551, 7, 6, 38, 131, 1043, 16, 3, 4, 171, 158, 896, 43, 161, 621, 1107, 7934, 3006, 161, 6, 437, 588, 2443, 7, 273, 48, 101, 16, 9, 143, 1207, 1230, 24]),\n",
              "       list([69, 1680, 596, 218, 3571, 11, 457, 13, 630, 5, 282, 80, 201, 6, 599, 3085, 2870, 2552, 377, 3277, 2108, 1519, 1, 5030, 596, 4615, 1123, 1520, 401, 137, 3451, 1139, 4805, 824, 3277, 4420, 268, 2553, 105, 1275, 824, 57, 1002, 9757, 2381, 8755, 3955, 201, 3007, 2018, 1418, 153, 1419, 2382, 5299, 213, 153, 5300, 824, 1650, 225, 13, 630, 41, 117, 71, 16, 6296, 273, 161, 166, 11, 925, 6746, 37]),\n",
              "       ...,\n",
              "       list([127, 44, 102, 27, 4072, 2463, 26, 922, 2567, 1937, 95, 8273, 285, 450, 127, 60, 159, 5844, 450, 91, 773, 956, 716, 44, 93, 5626, 2072, 28, 30, 853, 109, 398, 633, 1319, 159, 4, 30, 411, 26, 160, 30, 4011, 7, 688, 10, 7, 1378, 4, 30, 2381, 2107, 454, 27, 2295, 85, 159, 2, 1171, 530, 44, 93, 2, 405, 1886, 27, 777, 268, 204, 3244, 3212, 1514, 324, 268, 6810, 3212, 4458, 534, 280, 8433, 268, 6810, 3212, 4458, 534, 280, 27, 4072, 2463, 8273, 95, 620, 328, 2049, 29, 4562, 6131, 1937, 11, 2701, 6, 81, 97, 197, 8274, 204, 2, 1870, 77, 153, 764, 95, 1332, 8275, 41, 462, 1067, 8275, 402, 307, 1579, 2158, 552, 164, 29, 204, 2, 1870, 77, 153, 764, 95, 1332, 8275, 41, 462, 1067, 8275, 402, 307, 1579, 2158, 552, 164, 29, 6, 81, 153, 4773, 240, 2147, 204, 1411, 256, 77, 153, 89, 484, 2253, 14, 1348, 41, 1059, 1105, 2128, 2147, 240, 6, 427, 50, 85, 313, 24, 381, 2, 7, 1346, 20, 25, 930, 166, 903, 166, 718, 513, 7, 644, 1193, 316, 624, 93]),\n",
              "       list([105, 479, 68, 161, 132, 150, 41, 2815, 2942, 518, 3652, 96, 23, 775, 514, 2836, 239, 6504]),\n",
              "       list([184, 9456, 817, 445, 16, 470, 88, 8, 2664, 2511, 1385, 8768, 3744, 3499, 107, 3504, 880, 34, 569, 1, 350])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iosO_OU6ZFub",
        "outputId": "f39c29fa-8d7f-45c0-8594-6ab3508c18b1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def padding(sents, seq_len):\n",
        "    features = np.zeros((len(sents), seq_len), dtype = int)\n",
        "    for i, rev in enumerate(sents):\n",
        "        if len(rev) != 0:\n",
        "            features[i, -len(rev):] = np.array(rev)[:seq_len]\n",
        "    return features"
      ],
      "metadata": {
        "id": "zaXThayJZInX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = padding(X_train, 500)\n",
        "test_sentences = padding(X_test, 500)"
      ],
      "metadata": {
        "id": "Lqh78rRQZbsD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-OrkQzPaFSo",
        "outputId": "9e33becf-050e-45a6-e65f-80bed6151078"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,  238,   21, 4419],\n",
              "       [   0,    0,    0, ..., 1207, 1230,   24],\n",
              "       [   0,    0,    0, ...,  925, 6746,   37],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  316,  624,   93],\n",
              "       [   0,    0,    0, ..., 2836,  239, 6504],\n",
              "       [   0,    0,    0, ...,  569,    1,  350]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(np.array(train_sentences)), torch.from_numpy(np.array(y_train)))\n",
        "test_data = TensorDataset(torch.from_numpy(np.array(test_sentences)), torch.from_numpy(np.array(y_test)))"
      ],
      "metadata": {
        "id": "FWjh5cX2aKFg"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64"
      ],
      "metadata": {
        "id": "6_Tvzvenb4DX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(train_data, shuffle=True, batch_size = batch_size)\n",
        "testloader = DataLoader(test_data, shuffle= True, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "P_xorBkXbvRH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SBl66WUb2B4",
        "outputId": "b6a8e96b-58f9-4502-f4d6-829dddc5cd94"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        super(LSTM,self).__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional = bidirectional, dropout=dropout, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "       # Initialize hidden and cell states\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Frwd Propogation\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        out_frwd = hidden[-2,:,:]\n",
        "        out_reverse = hidden[-1,:,:]\n",
        "        out_reduced = torch.cat((out_frwd, out_reverse), dim = 1)\n",
        "        hidden = self.dropout(out_reduced)\n",
        "        hidden = torch.squeeze(hidden,1)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "rH4bgAEWcHIO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "vocab_size = len(vocab) + 1\n",
        "embedding_dim = 100\n",
        "hidden_dim = 64\n",
        "output_dim = 6\n",
        "n_layers = 2\n",
        "bidirection = True\n",
        "dropout = 0.5\n",
        "\n",
        "# Model\n",
        "model = LSTM(vocab_size, \n",
        "             embedding_dim, \n",
        "             hidden_dim, \n",
        "             output_dim, \n",
        "             n_layers, \n",
        "             bidirection, \n",
        "             dropout)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYgFripEoPGC",
        "outputId": "c969a7ee-76ef-4f8f-99db-16a0a48e176c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM(\n",
            "  (embedding): Embedding(10001, 100)\n",
            "  (lstm): LSTM(100, 64, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, trainloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # cleaning the cache of optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward propogation\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # computing loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # updating weights\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "def test(model, device, testloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            # Compute Loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.tolist())\n",
        "            y_pred.extend(predicted.tolist())\n",
        "\n",
        "    epoch_loss = running_loss / len(testloader.dataset)\n",
        "    epoch_accuracy = accuracy_score(y_true, y_pred)\n",
        "    return epoch_loss, epoch_accuracy\n"
      ],
      "metadata": {
        "id": "VZF9eqJIgjNB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGeXQPdFxn5b",
        "outputId": "7a61fe58-15a9-499d-c6cc-77707fa32835"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(10001, 100)\n",
              "  (lstm): LSTM(100, 64, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "train_losses, test_losses, test_accuracies = [], [], []\n",
        "for epoch in range(n_epochs):\n",
        "    #print(f'Epoch {epoch + 1} / {n_epochs}', end=' ')\n",
        "    \n",
        "    train_loss = train(model, device, trainloader, optimizer, criterion)\n",
        "    \n",
        "    test_loss, test_accuracy = test(model, device, testloader, criterion)\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    \n",
        "    if epoch %10 ==0: \n",
        "      print(f\"\\tTrain_loss {train_loss:.3f} | Epoch no.: {epoch+1}\")\n",
        "      print(f\"\\tTest_loss {test_loss:.3f} | Model_Acc: {test_accuracy*100:.2f}%\")\n",
        "      print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2RJOLGQgnpE",
        "outputId": "532bc05d-6332-4e6d-dd8d-f274d69360d5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain_loss 3.632 | Epoch no.: 1\n",
            "\tTest_loss 3.154 | Model_Acc: 32.50%\n",
            "\n",
            "\tTrain_loss 3.480 | Epoch no.: 11\n",
            "\tTest_loss 3.088 | Model_Acc: 25.83%\n",
            "\n",
            "\tTrain_loss 3.555 | Epoch no.: 21\n",
            "\tTest_loss 3.204 | Model_Acc: 31.97%\n",
            "\n",
            "\tTrain_loss 3.579 | Epoch no.: 31\n",
            "\tTest_loss 3.193 | Model_Acc: 33.86%\n",
            "\n",
            "\tTrain_loss 3.578 | Epoch no.: 41\n",
            "\tTest_loss 3.192 | Model_Acc: 40.15%\n",
            "\n",
            "\tTrain_loss 3.566 | Epoch no.: 51\n",
            "\tTest_loss 3.197 | Model_Acc: 38.79%\n",
            "\n",
            "\tTrain_loss 3.578 | Epoch no.: 61\n",
            "\tTest_loss 3.201 | Model_Acc: 39.70%\n",
            "\n",
            "\tTrain_loss 3.565 | Epoch no.: 71\n",
            "\tTest_loss 3.193 | Model_Acc: 41.21%\n",
            "\n",
            "\tTrain_loss 3.558 | Epoch no.: 81\n",
            "\tTest_loss 3.206 | Model_Acc: 41.67%\n",
            "\n",
            "\tTrain_loss 3.555 | Epoch no.: 91\n",
            "\tTest_loss 3.202 | Model_Acc: 41.74%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PvOXBvQZlMS2"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}